{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6883196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to path: d:\\omar\\Summer 2025\\CI\\project\\Neural-Network-Library_Advanced-Applications\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Automatically detect project root (folder containing `lib`)\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Added to path:\", project_root)\n",
    "\n",
    "\n",
    "from lib import Model, Dense, Tanh, Sigmoid, MSELoss, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11f73a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(model, X, y, epsilon=1e-5, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Numerical gradient checking using finite differences.\n",
    "    \"\"\"\n",
    "\n",
    "    # Analytical gradients\n",
    "    preds = model._forward(X)\n",
    "    model._loss.forward(preds, y)\n",
    "    grad = model._loss.backward()\n",
    "    model._backward(grad)\n",
    "\n",
    "    print(\"Running gradient check...\")\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if not hasattr(layer, \"parameters\"):\n",
    "            continue\n",
    "\n",
    "        for param, grad_analytic in layer.parameters():\n",
    "            it = np.nditer(param, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "            while not it.finished:\n",
    "                idx = it.multi_index\n",
    "                original_value = param[idx]\n",
    "\n",
    "                # f(theta + eps)\n",
    "                param[idx] = original_value + epsilon\n",
    "                plus_loss = model._loss.forward(model._forward(X), y)\n",
    "\n",
    "                # f(theta - eps)\n",
    "                param[idx] = original_value - epsilon\n",
    "                minus_loss = model._loss.forward(model._forward(X), y)\n",
    "\n",
    "                # restore\n",
    "                param[idx] = original_value\n",
    "\n",
    "                grad_numeric = (plus_loss - minus_loss) / (4 * epsilon)\n",
    "                grad_backprop = grad_analytic[idx]\n",
    "\n",
    "                rel_error = abs(grad_numeric - grad_backprop) / max(\n",
    "                    1e-8, abs(grad_numeric) + abs(grad_backprop)\n",
    "                )\n",
    "\n",
    "                if rel_error > tolerance:\n",
    "                    print(\"FAILED\")\n",
    "                    print(f\"Layer: {layer.__class__.__name__}\")\n",
    "                    print(f\"Index: {idx}\")\n",
    "                    print(f\"Numeric: {grad_numeric}\")\n",
    "                    print(f\"Backprop: {grad_backprop}\")\n",
    "                    print(f\"Relative error: {rel_error}\")\n",
    "                    return False\n",
    "\n",
    "                it.iternext()\n",
    "\n",
    "    print(\"Gradient check PASSED\")\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c635d065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gradient check...\n",
      "Gradient check PASSED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "X = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1]\n",
    "], dtype=float)\n",
    "\n",
    "y = np.array([\n",
    "    [0],\n",
    "    [1]\n",
    "], dtype=float)\n",
    "\n",
    "model = Model()\n",
    "model.add(Dense(4))\n",
    "#model.add(Tanh())\n",
    "model.add(Dense(1))\n",
    "#model.add(Sigmoid())\n",
    "\n",
    "\n",
    "model.compile(None, loss=MSELoss())\n",
    "model._forward(X)\n",
    "\n",
    "\n",
    "gradient_check(model, X, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
